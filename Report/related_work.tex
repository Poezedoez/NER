\section{Related work} \label{sec:rel}
Named-entity recognition(NER) comprises two tasks. Retrieval of named-entities is regarded as the primary task, and type classification of retrieved entities as the secondary task \cite{buitinck2012two}. In the paper of Buitinck and Marx an averaged perceptron is used for both stages, each consisting of its own feature parameters. The benefit of two-staged NER, in which a different algorithm per stage is used, lies in the opportunity of optimizing each algorithm individually.  

Recently, the most prevalent implementation of NER applies a supervised machine learning approach. An annotated corpus is required for apprehension of features (for instance syntax and context) that indicate the occurrence of a named-entity, as well as the type. This is state of the art as opposed to hand-written extraction rules. The downside of learning off an annotated corpus is the domain limitation that the corpus entails. Aditionally, a large training corpus is required for supervised learning, a corpus with domain resemblance to the goal domain of the NER-application. Currently, the only Dutch corpus that was made publicly available, is the CoNLL-2002 data set of news items that appeared in the Belgian newspaper \textit{De Morgen}. The data set contains 301,418 tokens with annotated Part-of-Speech(PoS) and IOB-tag\footnote{\url{https://en.wikipedia.org/wiki/Inside_Outside_Beginning}} hyphenated with entity type. IOB, short for inside-outside-beginning, is used to show if a token is the beginning of an entity consisting of multiple tokens; is second or one thereafter in the tag sequence; or outside, meaning not an entity itself or part of one.

A variety of classifier types can be chosen from, such as a memory-based learning classifier, a support-vector machine or a conditional random field.
No significant results are achieved by a combination of different classifiers, subsequently classifying based on weighted votes, as is shown by an in-depth evaluation of an ensemble of classifiers for Dutch  \cite{desmet2014fine}. Higher precision and recall are found by the optimization of features in a single classifier.

Likewise an \textit{unsupervised} machine learning approach has been suggested, for which no manual construction of gazetteers or annotated corpora is required \cite{kazama2008inducing}. While gazetteers are considered the most precise for NER, maintaining large dictionaries can be expensive. Clustering of verb-multi-noun dependencies allows for the automatic formation of gazetteers, avoiding said issue.

Frog is an expansion to TADPOLE \cite{bosch2007efficient}. The system is modular, composed of tokenization, lemmatization, chunking and morphological segmentation of word tokens. In addition dependency relations and NE's are detected in Dutch texts using the memory-based learning software TiMBL \cite{daelemans2004timbl}. Frog is designed for high accuracy, fast processing and low memory usage, qualifying itself to process numerous parliamentary items. Frog is trained on the SoNar corpus consisting of one million annotated and manually verified NER labels. The NER module has not been trained on PoS, but on the contextual relation between words and IOB-tags directly.  The assignment decision for each token is made with a look-up in memory, in which the instance base is stored. Unknown words are classified by a comparison to this instance base. The class of the instance that matches the contextual features of the unknown instance the closest, is chosen.  




